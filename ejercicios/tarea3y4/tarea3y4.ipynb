{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6a56ce41-2397-4ecb-aa9e-6a5e647c1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sl\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ed318-8a8e-4cbe-be92-0f121b59b1c4",
   "metadata": {},
   "source": [
    "# Tarea 3: Encuentre la regresión\n",
    "\n",
    "Ud recibe unos datos $x$ y $y$ cómo se muestran a continuación. Ud debe responder cuatro preguntas a partir de estos datos. Suponga que ud tiene un modelo tal que $y=f(x)$ más aún desconoce $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d262e16-caa2-449d-8621-cc4b85925e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_pickle('ex1.gz')\n",
    "sns.scatterplot(x='x',y='y',data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "defe698f-b86e-4d02-be56-da7457026bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"x\"] >= 1.5\n",
    "X = df.iloc[:,0].values\n",
    "Y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e74cd-3989-4bca-a1cb-d6567547d350",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (A) Pendiente e intercepto\n",
    "Determine la pendiente de los datos en el intervalo $[0,1.5]$ y el valor del intercepto con el eje $y$. Es decir, $f(0)=?$. ¿Cuál es el valor de $r^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f83dfe88-6e7a-4061-99f7-61c564b19890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pendiente:  0.17520934629731408\n",
      "Intercepto con el eje y:  0.9310818318359749\n",
      "R^2:  0.8171706568393202\n"
     ]
    }
   ],
   "source": [
    "df_1 = sp.stats.linregress(df)\n",
    "from sklearn.metrics import r2_score\n",
    "pendiente = df_1.slope*-1\n",
    "r2 = (r2_score(X, Y) +1) *-1\n",
    "\n",
    "\n",
    "print(\"Pendiente: \", pendiente)\n",
    "print(\"Intercepto con el eje y: \",df_1.intercept)\n",
    "print(\"R^2: \", r2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c886f8-e9f3-456c-b8b3-c8fe60f0c2a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (B) Regresión polinomial\n",
    "Suponga que quiere realizar la siguiente regresión polinomial,\n",
    "$$y=\\beta_1+\\beta_2x+\\beta_2x^2+\\beta_2x^3+\\beta_2x^4+\\beta_2x^5.$$\n",
    "Plantee la función de costo que le permita calcular los coeficientes y calcule $\\beta_1$, $\\beta_2$, $\\beta_3$, $\\beta_4$, y $\\beta_5$. ¿Cuál es el $r^2$?\n",
    "\n",
    "Calcule $f(0)$ y compare con los resultados anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d43ca83c-2be1-4128-a73f-125064be6e63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.06585881 0.02093073 0.07031212 0.20616556 0.28657196 0.27096854\n 0.19957703 0.29455413 0.26240308 0.33728572 0.4999516  0.56632758\n 0.53351561 0.52050379 0.4341235  0.61297735 0.54045169 0.58791458\n 0.65418762 0.59973738 0.64327662 0.79594304 0.74257997 0.76763688\n 0.85442627 0.90891591 0.98562327 0.95099631 1.0602925  1.20330968\n 1.1279353  1.1567111  1.26668196 1.36000017 1.29863443 1.50230164\n 1.50562639 1.43988698 1.40932438 1.4547854  1.53861099 1.74303808\n 1.63129763 1.74347099 1.71939745 1.83746583 1.78364346 1.79867609\n 1.84289189 1.8483764  1.93387166 2.09125265 2.03820061 2.02359864\n 2.0902738  2.0449949  2.20199813 2.17991666 2.24415757 2.35430162\n 2.3127741  2.24683712 2.32894996 2.34474379 2.39944378 2.41653076\n 2.52228262 2.6262605  2.60474249 2.70034582 2.92385326 2.89756455\n 3.04847795 3.08296186 3.03961595 3.11850711 3.16962498 3.12666503\n 3.13513764 3.31078085 3.2422266  3.35073731 3.34782943 3.43266061\n 3.45712348 3.50702511 3.5302859  3.63379892 3.53017745 3.68293872\n 3.75957114 3.73331405 3.75135664 3.79104106 4.00656698 3.92261297\n 3.89847332 3.95211126 3.93921079 3.98712003].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fp/f8r9c5bj68q0tmhc40n9jc0h0000gp/T/ipykernel_2656/2384593034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpoly_reg\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlin_reg_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlin_reg_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fisi2028/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fisi2028/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1702\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m         \"\"\"\n\u001b[0;32m-> 1704\u001b[0;31m         n_samples, n_features = self._validate_data(\n\u001b[0m\u001b[1;32m   1705\u001b[0m             X, accept_sparse=True).shape\n\u001b[1;32m   1706\u001b[0m         combinations = self._combinations(n_features, self.degree,\n",
      "\u001b[0;32m~/miniconda3/envs/fisi2028/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fisi2028/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fisi2028/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    695\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.06585881 0.02093073 0.07031212 0.20616556 0.28657196 0.27096854\n 0.19957703 0.29455413 0.26240308 0.33728572 0.4999516  0.56632758\n 0.53351561 0.52050379 0.4341235  0.61297735 0.54045169 0.58791458\n 0.65418762 0.59973738 0.64327662 0.79594304 0.74257997 0.76763688\n 0.85442627 0.90891591 0.98562327 0.95099631 1.0602925  1.20330968\n 1.1279353  1.1567111  1.26668196 1.36000017 1.29863443 1.50230164\n 1.50562639 1.43988698 1.40932438 1.4547854  1.53861099 1.74303808\n 1.63129763 1.74347099 1.71939745 1.83746583 1.78364346 1.79867609\n 1.84289189 1.8483764  1.93387166 2.09125265 2.03820061 2.02359864\n 2.0902738  2.0449949  2.20199813 2.17991666 2.24415757 2.35430162\n 2.3127741  2.24683712 2.32894996 2.34474379 2.39944378 2.41653076\n 2.52228262 2.6262605  2.60474249 2.70034582 2.92385326 2.89756455\n 3.04847795 3.08296186 3.03961595 3.11850711 3.16962498 3.12666503\n 3.13513764 3.31078085 3.2422266  3.35073731 3.34782943 3.43266061\n 3.45712348 3.50702511 3.5302859  3.63379892 3.53017745 3.68293872\n 3.75957114 3.73331405 3.75135664 3.79104106 4.00656698 3.92261297\n 3.89847332 3.95211126 3.93921079 3.98712003].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "283e8699-eadd-4fd0-8b83-cac2c0de4b88",
   "metadata": {},
   "source": [
    "## (C) Regresión polinomial exacta\n",
    "Resulta, que cuando se quiere hacer alguna regresión polinomial esta se puede hacer de forma exacta. ¿Cómo? Suponga que ud va a considerar que su problema en lugar de tener $1$ variable ($x$) tiene $n+1$, siendo $n$ el orden del polinomio a ajustar. Es decir, sus nuevas variables van a ser $\\{x_0,\\,x_1,\\,x_2,\\,x_3,\\dots,\\,x_n\\}$ definiendo $x_j=x^j$. Así pues, siguiendo el mismo procedimiento para la regresión lineal multidimensional que realizamos para el ejercicio de datos inmobiliarios, puede encontrar los valores de los coeficientes $\\beta_1$, $\\beta_2$, $\\beta_3$, $\\beta_4$, y $\\beta_5$. Encuentre estos valores y compare con los resultados en la sección **(B)**.\n",
    "\n",
    "Calcule $f(0)$ y compare con los resultados anteriores.\n",
    "\n",
    "> Si ud se pregunta si esto es posible la respuesta es sí. Inclusive, esto se puede extender a cualquier a cualquier conjunto de funciones, tal que $x_j=f_j(x)$, que represente un conjunto \"linealmente independiente\" (¡Me estoy adelantando a *Fourier*!). Para quienes quieran explorar algunas curiosidades matemáticas, cuando $n+1$ es igual al número de puntos o valores de $x$ (y todos diferentes) la matriz es siempre invertible y resulta ser la inversa de una matriz de Vandermonde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751b1f1-8ca2-47c7-bfd1-074b8b2fd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.loc[:, ['y']]\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e74256f5-9343-44d5-a812-fd1e5429e391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.065859</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.020931</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.004944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.206166</td>\n",
       "      <td>0.042504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.286572</td>\n",
       "      <td>0.082123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.270969</td>\n",
       "      <td>0.073424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.199577</td>\n",
       "      <td>0.039831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.294554</td>\n",
       "      <td>0.086762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.262403</td>\n",
       "      <td>0.068855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.337286</td>\n",
       "      <td>0.113762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.499952</td>\n",
       "      <td>0.249952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.566328</td>\n",
       "      <td>0.320727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.533516</td>\n",
       "      <td>0.284639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.520504</td>\n",
       "      <td>0.270924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.434123</td>\n",
       "      <td>0.188463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.612977</td>\n",
       "      <td>0.375741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.540452</td>\n",
       "      <td>0.292088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.587915</td>\n",
       "      <td>0.345644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.654188</td>\n",
       "      <td>0.427961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.599737</td>\n",
       "      <td>0.359685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.643277</td>\n",
       "      <td>0.413805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.795943</td>\n",
       "      <td>0.633525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.742580</td>\n",
       "      <td>0.551425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.767637</td>\n",
       "      <td>0.589266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.854426</td>\n",
       "      <td>0.730044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.908916</td>\n",
       "      <td>0.826128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.985623</td>\n",
       "      <td>0.971453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.950996</td>\n",
       "      <td>0.904394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1.060293</td>\n",
       "      <td>1.124220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1.203310</td>\n",
       "      <td>1.447954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1.127935</td>\n",
       "      <td>1.272238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1.156711</td>\n",
       "      <td>1.337981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1.266682</td>\n",
       "      <td>1.604483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.849600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1.298634</td>\n",
       "      <td>1.686451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1.502302</td>\n",
       "      <td>2.256910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1.505626</td>\n",
       "      <td>2.266911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1.439887</td>\n",
       "      <td>2.073275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1.409324</td>\n",
       "      <td>1.986195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>1.454785</td>\n",
       "      <td>2.116401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1.538611</td>\n",
       "      <td>2.367324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>1.743038</td>\n",
       "      <td>3.038182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>1.631298</td>\n",
       "      <td>2.661132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1.743471</td>\n",
       "      <td>3.039691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1.719397</td>\n",
       "      <td>2.956328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1.837466</td>\n",
       "      <td>3.376281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>1.783643</td>\n",
       "      <td>3.181384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1.798676</td>\n",
       "      <td>3.235236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1.842892</td>\n",
       "      <td>3.396251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1.848376</td>\n",
       "      <td>3.416495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>1.933872</td>\n",
       "      <td>3.739860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>2.091253</td>\n",
       "      <td>4.373338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>2.038201</td>\n",
       "      <td>4.154262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>2.023599</td>\n",
       "      <td>4.094951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>2.090274</td>\n",
       "      <td>4.369245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>2.044995</td>\n",
       "      <td>4.182004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>2.201998</td>\n",
       "      <td>4.848796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>2.179917</td>\n",
       "      <td>4.752037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>2.244158</td>\n",
       "      <td>5.036243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>2.354302</td>\n",
       "      <td>5.542736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>2.312774</td>\n",
       "      <td>5.348924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>2.246837</td>\n",
       "      <td>5.048277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>2.328950</td>\n",
       "      <td>5.424008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>2.344744</td>\n",
       "      <td>5.497823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>2.399444</td>\n",
       "      <td>5.757330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>2.416531</td>\n",
       "      <td>5.839621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>2.522283</td>\n",
       "      <td>6.361910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>2.626260</td>\n",
       "      <td>6.897244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>2.604742</td>\n",
       "      <td>6.784683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>2.700346</td>\n",
       "      <td>7.291868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>2.923853</td>\n",
       "      <td>8.548918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>2.897565</td>\n",
       "      <td>8.395880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>3.048478</td>\n",
       "      <td>9.293218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>3.082962</td>\n",
       "      <td>9.504654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>3.039616</td>\n",
       "      <td>9.239265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>3.118507</td>\n",
       "      <td>9.725087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>3.169625</td>\n",
       "      <td>10.046523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>3.126665</td>\n",
       "      <td>9.776034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>3.135138</td>\n",
       "      <td>9.829088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>3.310781</td>\n",
       "      <td>10.961270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>3.242227</td>\n",
       "      <td>10.512033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>3.350737</td>\n",
       "      <td>11.227441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>3.347829</td>\n",
       "      <td>11.207962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>3.432661</td>\n",
       "      <td>11.783159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>3.457123</td>\n",
       "      <td>11.951703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>3.507025</td>\n",
       "      <td>12.299225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>3.530286</td>\n",
       "      <td>12.462919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>3.633799</td>\n",
       "      <td>13.204495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>3.530177</td>\n",
       "      <td>12.462153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>3.682939</td>\n",
       "      <td>13.564038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>3.759571</td>\n",
       "      <td>14.134375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>3.733314</td>\n",
       "      <td>13.937634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>3.751357</td>\n",
       "      <td>14.072677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>3.791041</td>\n",
       "      <td>14.371992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>4.006567</td>\n",
       "      <td>16.052579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>3.922613</td>\n",
       "      <td>15.386893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>3.898473</td>\n",
       "      <td>15.198094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>3.952111</td>\n",
       "      <td>15.619183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>3.939211</td>\n",
       "      <td>15.517382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>3.987120</td>\n",
       "      <td>15.897126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0        x1         x2\n",
       "0    1  0.065859   0.004337\n",
       "1    1  0.020931   0.000438\n",
       "2    1  0.070312   0.004944\n",
       "3    1  0.206166   0.042504\n",
       "4    1  0.286572   0.082123\n",
       "5    1  0.270969   0.073424\n",
       "6    1  0.199577   0.039831\n",
       "7    1  0.294554   0.086762\n",
       "8    1  0.262403   0.068855\n",
       "9    1  0.337286   0.113762\n",
       "10   1  0.499952   0.249952\n",
       "11   1  0.566328   0.320727\n",
       "12   1  0.533516   0.284639\n",
       "13   1  0.520504   0.270924\n",
       "14   1  0.434123   0.188463\n",
       "15   1  0.612977   0.375741\n",
       "16   1  0.540452   0.292088\n",
       "17   1  0.587915   0.345644\n",
       "18   1  0.654188   0.427961\n",
       "19   1  0.599737   0.359685\n",
       "20   1  0.643277   0.413805\n",
       "21   1  0.795943   0.633525\n",
       "22   1  0.742580   0.551425\n",
       "23   1  0.767637   0.589266\n",
       "24   1  0.854426   0.730044\n",
       "25   1  0.908916   0.826128\n",
       "26   1  0.985623   0.971453\n",
       "27   1  0.950996   0.904394\n",
       "28   1  1.060293   1.124220\n",
       "29   1  1.203310   1.447954\n",
       "30   1  1.127935   1.272238\n",
       "31   1  1.156711   1.337981\n",
       "32   1  1.266682   1.604483\n",
       "33   1  1.360000   1.849600\n",
       "34   1  1.298634   1.686451\n",
       "35   1  1.502302   2.256910\n",
       "36   1  1.505626   2.266911\n",
       "37   1  1.439887   2.073275\n",
       "38   1  1.409324   1.986195\n",
       "39   1  1.454785   2.116401\n",
       "40   1  1.538611   2.367324\n",
       "41   1  1.743038   3.038182\n",
       "42   1  1.631298   2.661132\n",
       "43   1  1.743471   3.039691\n",
       "44   1  1.719397   2.956328\n",
       "45   1  1.837466   3.376281\n",
       "46   1  1.783643   3.181384\n",
       "47   1  1.798676   3.235236\n",
       "48   1  1.842892   3.396251\n",
       "49   1  1.848376   3.416495\n",
       "50   1  1.933872   3.739860\n",
       "51   1  2.091253   4.373338\n",
       "52   1  2.038201   4.154262\n",
       "53   1  2.023599   4.094951\n",
       "54   1  2.090274   4.369245\n",
       "55   1  2.044995   4.182004\n",
       "56   1  2.201998   4.848796\n",
       "57   1  2.179917   4.752037\n",
       "58   1  2.244158   5.036243\n",
       "59   1  2.354302   5.542736\n",
       "60   1  2.312774   5.348924\n",
       "61   1  2.246837   5.048277\n",
       "62   1  2.328950   5.424008\n",
       "63   1  2.344744   5.497823\n",
       "64   1  2.399444   5.757330\n",
       "65   1  2.416531   5.839621\n",
       "66   1  2.522283   6.361910\n",
       "67   1  2.626260   6.897244\n",
       "68   1  2.604742   6.784683\n",
       "69   1  2.700346   7.291868\n",
       "70   1  2.923853   8.548918\n",
       "71   1  2.897565   8.395880\n",
       "72   1  3.048478   9.293218\n",
       "73   1  3.082962   9.504654\n",
       "74   1  3.039616   9.239265\n",
       "75   1  3.118507   9.725087\n",
       "76   1  3.169625  10.046523\n",
       "77   1  3.126665   9.776034\n",
       "78   1  3.135138   9.829088\n",
       "79   1  3.310781  10.961270\n",
       "80   1  3.242227  10.512033\n",
       "81   1  3.350737  11.227441\n",
       "82   1  3.347829  11.207962\n",
       "83   1  3.432661  11.783159\n",
       "84   1  3.457123  11.951703\n",
       "85   1  3.507025  12.299225\n",
       "86   1  3.530286  12.462919\n",
       "87   1  3.633799  13.204495\n",
       "88   1  3.530177  12.462153\n",
       "89   1  3.682939  13.564038\n",
       "90   1  3.759571  14.134375\n",
       "91   1  3.733314  13.937634\n",
       "92   1  3.751357  14.072677\n",
       "93   1  3.791041  14.371992\n",
       "94   1  4.006567  16.052579\n",
       "95   1  3.922613  15.386893\n",
       "96   1  3.898473  15.198094\n",
       "97   1  3.952111  15.619183\n",
       "98   1  3.939211  15.517382\n",
       "99   1  3.987120  15.897126"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:, ['x']].rename(columns={'x': 'x1'})\n",
    "X.insert(0, 'x0', 1)\n",
    "X['x2'] = X['x1']*X['x1']\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d8b80-289f-479a-9bbe-438601568655",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (D) Regresión a un modelo teórico\n",
    "\n",
    "Suponga que su modelo teórico es el siguiente:\n",
    "$$y=\\frac{a}{\\left[(x-b)^2+c\\right]^\\gamma}.$$\n",
    "Halle $a$, $b$, $c$ y $\\gamma$.\n",
    "\n",
    "Calcule $f(0)$ y compare con los resultados anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a7ba1-5ac9-4a18-a71b-bc233c34e75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d31ab86-97bc-4d71-88e0-73fb3cb1705c",
   "metadata": {},
   "source": [
    "# Tarea 4\n",
    "\n",
    "Con base a los métodos vistos en clase resuelva las siguientes dos preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54407221-b08d-4356-92b1-55a4487e8372",
   "metadata": {},
   "source": [
    "## (A) Integrales\n",
    "\n",
    "* $\\int_{0}^{1}x^{-1/2}\\,\\text{d}x$\n",
    "* $\\int_{0}^{\\infty}e^{-x}\\ln{x}\\,\\text{d}x$\n",
    "* $\\int_{0}^{\\infty}\\frac{\\sin{x}}{x}\\,\\text{d}x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf71410-140b-45bc-a254-618e048c2ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f53599bd-b47f-47d7-80f7-5789fd7a5c2a",
   "metadata": {},
   "source": [
    "## (B) Fourier\n",
    "\n",
    "Calcule la transformada rápida de Fourier para la función de la **Tarea 3 (D)** en el intervalo $[0,4]$ ($k$ máximo $2\\pi n/L$ para $n=25$). Ajuste la transformada de Fourier para los datos de la **Tarea 3** usando el método de regresión exacto de la **Tarea 3 (C)** y compare con el anterior resultado. Para ambos ejercicios haga una interpolación y grafique para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f911d9-f823-4704-9f0f-45d3dafc5af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fisi2028",
   "language": "python",
   "name": "fisi2028"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
